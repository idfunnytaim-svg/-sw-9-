{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10fd8683-2912-4e2e-a58b-089a56455b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "loading checkpoint from: C:\\Users\\USER\\Downloads\\workspace\\shared_alexnet_grasp.pth\n",
      "num_classes: 15\n",
      "orig_ids: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15)]\n",
      "model loaded.\n",
      "test calibrated mapping w_n -> angle:\n",
      "  w_n=0.00 -> angle=70.0\n",
      "  w_n=0.05 -> angle=70.0\n",
      "  w_n=0.15 -> angle=48.3\n",
      "  w_n=0.25 -> angle=26.7\n",
      "  w_n=0.35 -> angle=5.0\n",
      "  w_n=0.50 -> angle=5.0\n",
      "  w_n=1.00 -> angle=5.0\n",
      "opening serial: COM4\n",
      "serial opened.\n",
      "웹캠 시작. 'Grasp + Gripper' 창에서 'q' 키를 누르면 종료됩니다.\n",
      "[frame 50] raw w_n=-0.1182, grip_angle=70\n",
      "[frame 100] raw w_n=0.0307, grip_angle=70\n",
      "[frame 150] raw w_n=0.1894, grip_angle=39\n",
      "[frame 200] raw w_n=0.1567, grip_angle=46\n",
      "[frame 250] raw w_n=0.1396, grip_angle=50\n",
      "[frame 300] raw w_n=0.1344, grip_angle=51\n",
      "[frame 350] raw w_n=0.1453, grip_angle=49\n",
      "[frame 400] raw w_n=0.3233, grip_angle=10\n",
      "[frame 450] raw w_n=-0.0032, grip_angle=70\n",
      "[frame 500] raw w_n=-0.0089, grip_angle=70\n",
      "[frame 550] raw w_n=-0.0254, grip_angle=70\n",
      "[frame 600] raw w_n=0.1265, grip_angle=53\n",
      "[frame 650] raw w_n=0.1058, grip_angle=57\n",
      "[frame 700] raw w_n=0.1037, grip_angle=58\n",
      "[frame 750] raw w_n=0.1197, grip_angle=54\n",
      "[frame 800] raw w_n=0.1230, grip_angle=54\n",
      "[frame 850] raw w_n=0.2304, grip_angle=30\n",
      "사용자 q 입력으로 종료.\n",
      "캠/시리얼 종료.\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# SharedAlexNet 로드 + 웹캠 + 그리퍼 서보 제어\n",
    "# - CPU 사용\n",
    "# - MAX_FRAMES까지는 계속 돌고, 'q' 누르면 즉시 종료\n",
    "# - w_n 분포를 고려한 보정 매핑 사용 (GRIP_CLOSE를 70도로 제한)\n",
    "# ======================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import serial, time\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "# -----------------------------\n",
    "# 0. 사용자 환경 설정\n",
    "# -----------------------------\n",
    "CKPT_PATH  = r\"C:\\Users\\USER\\Downloads\\workspace\\shared_alexnet_grasp.pth\"  # 모델 pth 경로\n",
    "PORT       = \"COM4\"     # Arduino IDE -> 도구 -> 포트 에서 확인한 포트 번호\n",
    "BAUD       = 115200\n",
    "MAX_FRAMES = 1000       # 이 프레임 수에 도달하면 자동 종료\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. SharedAlexNet 정의\n",
    "# -----------------------------\n",
    "class SharedAlexNet(nn.Module):\n",
    "    def __init__(self, base_model, num_classes, grasp_dim=6):\n",
    "        super().__init__()\n",
    "        self.features = base_model.features\n",
    "        self.avgpool  = base_model.avgpool\n",
    "        self.shared_fc = nn.Sequential(*list(base_model.classifier[:-1]))\n",
    "        in_features = base_model.classifier[-1].in_features  # 4096\n",
    "\n",
    "        self.cls_head = nn.Linear(in_features, num_classes)   # 분류용\n",
    "        self.reg_head = nn.Linear(in_features, grasp_dim)     # (cx, cy, h, w, sin2θ, cos2θ)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        z = self.shared_fc(x)\n",
    "        logits = self.cls_head(z)\n",
    "        grasps = self.reg_head(z)\n",
    "        return logits, grasps\n",
    "\n",
    "# -----------------------------\n",
    "# 2. 체크포인트 로드\n",
    "# -----------------------------\n",
    "print(\"loading checkpoint from:\", CKPT_PATH)\n",
    "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "orig_ids      = ckpt[\"orig_ids\"]\n",
    "id_to_idx     = ckpt[\"id_to_idx\"]\n",
    "idx_to_id     = {v: k for k, v in id_to_idx.items()}\n",
    "imagenet_mean = ckpt[\"imagenet_mean\"]\n",
    "imagenet_std  = ckpt[\"imagenet_std\"]\n",
    "\n",
    "num_classes = len(orig_ids)\n",
    "GRASP_DIM   = 6\n",
    "\n",
    "print(\"num_classes:\", num_classes)\n",
    "print(\"orig_ids:\", orig_ids)\n",
    "\n",
    "try:\n",
    "    weights = models.AlexNet_Weights.IMAGENET1K_V1\n",
    "    base_alex = models.alexnet(weights=weights)\n",
    "except AttributeError:\n",
    "    base_alex = models.alexnet(pretrained=True)\n",
    "\n",
    "model = SharedAlexNet(base_alex, num_classes=num_classes, grasp_dim=GRASP_DIM)\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "print(\"model loaded.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. 전처리 정의\n",
    "# -----------------------------\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# 4. 보정된 w_n -> 그리퍼 각도 매핑\n",
    "#    - Cornell에서 실제로 나오는 w_n 범위 [W_MIN, W_MAX]를\n",
    "#      서보 각도 [GRIP_OPEN, GRIP_CLOSE]에 선형 매핑\n",
    "#    - GRIP_CLOSE를 70도로 제한해서 완전 90도까지 닫히지 않게 함\n",
    "# -----------------------------\n",
    "W_MIN = 0.05   # Cornell grasp 폭 하한 근처 (대략값, 나중에 CSV 통계로 조정 가능)\n",
    "W_MAX = 0.35   # Cornell grasp 폭 상한 근처 (대략값)\n",
    "\n",
    "GRIP_OPEN  = 5.0   # 완전 벌림 각도 (하드웨어에 맞게 약간 닫힌 상태에서 시작)\n",
    "GRIP_CLOSE = 70.0  # 최대 닫힘 각도 (90이 아니라 70까지만 닫히게 제한)\n",
    "\n",
    "def w_to_grip_angle_calibrated(w_n):\n",
    "    \"\"\"\n",
    "    w_n: 네트워크 예측 정규화 grasp 폭 (0~1 근처)\n",
    "\n",
    "    1) [W_MIN, W_MAX] 로 클램프\n",
    "    2) 이 구간을 0~1로 다시 정규화\n",
    "    3) 0~1 를 서보 각도 [GRIP_OPEN, GRIP_CLOSE]에 매핑\n",
    "       w_n = W_MIN  -> angle = GRIP_CLOSE (가장 닫힘)\n",
    "       w_n = W_MAX  -> angle = GRIP_OPEN  (가장 벌림)\n",
    "    \"\"\"\n",
    "    w = float(w_n)\n",
    "\n",
    "    # 1) Cornell 데이터 범위로 클램프\n",
    "    if w < W_MIN:\n",
    "        w_clip = W_MIN\n",
    "    elif w > W_MAX:\n",
    "        w_clip = W_MAX\n",
    "    else:\n",
    "        w_clip = w\n",
    "\n",
    "    # 2) [W_MIN, W_MAX] -> [0, 1] 정규화\n",
    "    alpha = (w_clip - W_MIN) / (W_MAX - W_MIN)  # alpha in [0, 1]\n",
    "\n",
    "    # 3) alpha -> 각도\n",
    "    angle = GRIP_CLOSE - alpha * (GRIP_CLOSE - GRIP_OPEN)\n",
    "    return angle\n",
    "\n",
    "print(\"test calibrated mapping w_n -> angle:\")\n",
    "for w in [0.0, 0.05, 0.15, 0.25, 0.35, 0.5, 1.0]:\n",
    "    a = w_to_grip_angle_calibrated(w)\n",
    "    print(f\"  w_n={w:.2f} -> angle={a:.1f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. 시리얼 오픈\n",
    "# -----------------------------\n",
    "print(\"opening serial:\", PORT)\n",
    "ser = serial.Serial(PORT, BAUD, timeout=1)\n",
    "time.sleep(2)\n",
    "print(\"serial opened.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. 웹캠 오픈\n",
    "# -----------------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"웹캠을 열 수 없습니다.\")\n",
    "    ser.close()\n",
    "    raise SystemExit\n",
    "\n",
    "print(\"웹캠 시작. 'Grasp + Gripper' 창에서 'q' 키를 누르면 종료됩니다.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7. 메인 루프\n",
    "# -----------------------------\n",
    "frame_idx = 0\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"프레임을 읽지 못했습니다.\")\n",
    "            break\n",
    "\n",
    "        # BGR -> RGB -> PIL\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = PILImage.fromarray(rgb)\n",
    "\n",
    "        x = preprocess(pil_img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits, grasp = model(x)\n",
    "\n",
    "        cx_n, cy_n, h_n, w_n, sin2t, cos2t = grasp[0].cpu().numpy()\n",
    "\n",
    "        theta = 0.5 * math.atan2(sin2t, cos2t)\n",
    "        theta_deg = theta * 180.0 / math.pi\n",
    "\n",
    "        # 보정된 매핑 사용\n",
    "        grip_angle = int(w_to_grip_angle_calibrated(w_n))\n",
    "\n",
    "        # 아두이노로 전송\n",
    "        cmd = f\"{grip_angle}\\n\"\n",
    "        ser.write(cmd.encode(\"ascii\"))\n",
    "\n",
    "        # 텍스트 오버레이\n",
    "        text = f\"theta={theta_deg:.1f}, w={w_n:.3f}, grip={grip_angle}\"\n",
    "        cv2.putText(frame, text, (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Grasp + Gripper\", frame)\n",
    "\n",
    "        # 50프레임마다 상태 출력 (디버깅용)\n",
    "        frame_idx += 1\n",
    "        if frame_idx % 50 == 0:\n",
    "            print(f\"[frame {frame_idx}] raw w_n={w_n:.4f}, grip_angle={grip_angle}\")\n",
    "\n",
    "        # q 키 누르면 종료\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            print(\"사용자 q 입력으로 종료.\")\n",
    "            break\n",
    "\n",
    "        # 프레임 제한에 도달하면 종료 (너무 오래 돌지 않도록)\n",
    "        if frame_idx >= MAX_FRAMES:\n",
    "            print(f\"MAX_FRAMES({MAX_FRAMES}) 도달, 자동 종료.\")\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KeyboardInterrupt로 종료.\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    ser.close()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"캠/시리얼 종료.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a93a48-8482-40a0-9217-c285837ba445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
